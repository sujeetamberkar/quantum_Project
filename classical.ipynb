{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentations \n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture \n",
    "class ClassicalCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1st Convo layer\n",
    "        self.conv1 = nn.Conv2d(1, 2, kernel_size=5)\n",
    "        # Input: Takes one Greyscale image as Input\n",
    "        # Output:  2 feature maps\n",
    "        # Kernel: 5x5\n",
    "\n",
    "        # 2nd Convo layer\n",
    "        self.conv2 = nn.Conv2d(2, 16, kernel_size=5) # 2nd Convo layer\n",
    "        # Input: 2 input channel\n",
    "        # Output:  16 feature maps\n",
    "        # Kernel: 5x5\n",
    "\n",
    "        # regularization : Drupout Layer\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        \n",
    "        # 1st Fully connected layer:\n",
    "        # Flat Convolutional features (400) ---> 64 features\n",
    "        # converts convolutional features to dense representation\n",
    "        # For 32x32 CIFAR images, after convolutions and pooling we get 16x5x5=400 features\n",
    "        self.fc1 = nn.Linear(400, 64)  # Dense layer\n",
    "\n",
    "        # 2nd Fully connected layer:\n",
    "        # 64 features ----> 2 features\n",
    "        self.fc2 = nn.Linear(64, 2)  # Output to 2 classes\n",
    "        \n",
    "        # 3rd Fully Connected Layer:\n",
    "        # 2 features ----> 1 featuture\n",
    "        self.fc3 = nn.Linear(2, 1)\n",
    "\n",
    "        # 4th Fully Connected Layer:\n",
    "        # 1 feature ------> 2 features\n",
    "        self.fc4 = nn.Linear(1, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1st Layer\n",
    "        x = F.relu(self.conv1(x)) # Relu Function\n",
    "        x = F.max_pool2d(x, 2) # Max Pooling\n",
    "\n",
    "        # 2nd Convv Layer \n",
    "        x = F.relu(self.conv2(x)) # ReLU activation\n",
    "        x = F.max_pool2d(x, 2)    # Max Pooling\n",
    "\n",
    "        # dropout for regularization\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Flatten layer\n",
    "        # Flatten the 3D tensor to 1D for dense layers\n",
    "        x = x.view(x.shape[0], -1)  # Shape becomes [batch_size, 400]\n",
    "        \n",
    "        # 1st Fully connected layer:\n",
    "        x = F.relu(self.fc1(x)) # ReLU\n",
    "\n",
    "        # 2nd Fully connected layer:\n",
    "        x = self.fc2(x) # No activation\n",
    "\n",
    "        # 3rd Fully Connected Layer:\n",
    "        x = F.relu(self.fc3(x)) # ReLU\n",
    "\n",
    "        # 4th Fully Connected Layer:\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1) # softmax Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ClassicalCNN                             [1, 2]                    --\n",
       "├─Conv2d: 1-1                            [1, 2, 28, 28]            52\n",
       "├─Conv2d: 1-2                            [1, 16, 10, 10]           816\n",
       "├─Dropout2d: 1-3                         [1, 16, 5, 5]             --\n",
       "├─Linear: 1-4                            [1, 64]                   25,664\n",
       "├─Linear: 1-5                            [1, 2]                    130\n",
       "├─Linear: 1-6                            [1, 1]                    3\n",
       "├─Linear: 1-7                            [1, 2]                    4\n",
       "==========================================================================================\n",
       "Total params: 26,669\n",
       "Trainable params: 26,669\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 0.14\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "demo_Model = ClassicalCNN()\n",
    "summary(demo_Model, input_size=(1, 1, 32, 32))  # CIFAR-10 images: 32×32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(digits=10, length=2):\n",
    "    \"\"\"\n",
    "    Generate combinations of CIFAR-10\n",
    "    \"\"\"\n",
    "    result = []    \n",
    "    if length == 2:\n",
    "        for i in range(digits):\n",
    "            for j in range(i + 1, digits):\n",
    "                result.append([i, j])\n",
    "    else:\n",
    "        def backtrack(current_combination, start_index):\n",
    "            if len(current_combination) == length:\n",
    "                result.append(current_combination[:])\n",
    "                return\n",
    "            for i in range(start_index, digits):\n",
    "                current_combination.append(i)\n",
    "                backtrack(current_combination, i + 1)\n",
    "                current_combination.pop()\n",
    "        \n",
    "        backtrack([], 0)\n",
    "    \n",
    "    return result\n",
    "a = generate_combinations()\n",
    "print(f\"Number of combinations: {len(a)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(class_indices):\n",
    "    print(f\"\\n\\n=== Evaluating classes {class_indices} ===\")  \n",
    "# All Possible classes       \n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# Select Class     \n",
    "    selected_classes = [class_names[idx] for idx in class_indices]\n",
    "    print(f\"Selected classes: {selected_classes}\")\n",
    "\n",
    "# Training    \n",
    "# Filter data\n",
    "    filtered_train_data = [(image, label) for image, label in trainset if label in class_indices]\n",
    "    filtered_train_images, filtered_train_labels = zip(*filtered_train_data)    \n",
    "# Map labels to binary \n",
    "    filtered_train_labels = [0 if label == class_indices[0] else 1 for label in filtered_train_labels]\n",
    "\n",
    "# Testing \n",
    "# Filter data\n",
    "    filtered_test_data = [(image, label) for image, label in testset if label in class_indices]\n",
    "    filtered_test_images, filtered_test_labels = zip(*filtered_test_data)    \n",
    "# Map labels to binary \n",
    "    filtered_test_labels = [0 if label == class_indices[0] else 1 for label in filtered_test_labels]\n",
    "    \n",
    "    \n",
    "# Create datasets and loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.stack(filtered_train_images),\n",
    "        torch.tensor(filtered_train_labels)\n",
    "        )\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.stack(filtered_test_images),\n",
    "        torch.tensor(filtered_test_labels)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Use the best available device to run \n",
    "# MPS for Mac, CUDA for NVIDIA GPU, or CPU    \n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize the CNN model\n",
    "    model = ClassicalCNN().to(device)\n",
    "\n",
    "    criterion = nn.NLLLoss() # loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # optimizer\n",
    "    \n",
    "    num_epochs = 10 # Number of Epochs\n",
    "\n",
    "    # Training of Model \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = []\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Move data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Zero gradients before backward pass\n",
    "            optimizer.zero_grad(set_to_none=True) \n",
    "\n",
    "            output = model(data) # Forward pass\n",
    "            loss = criterion(output, target) # Calculate loss\n",
    "            loss.backward() # Backward pass   \n",
    "            optimizer.step() # Update weights\n",
    "            total_loss.append(loss.item()) # Track loss\n",
    "        \n",
    "\n",
    "            # Track Progress:\n",
    "            \"\"\"\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] '\n",
    "                  f'Loss: {loss.item():.4f}')\n",
    "    \n",
    "            \"\"\" \n",
    "        # average loss for the epoch    \n",
    "        avg_loss = sum(total_loss) / len(total_loss)\n",
    "        # print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # print('Finished Training')\n",
    "    \n",
    "    def evaluate_model(model, test_loader, device): # Evaluate Model \n",
    "        model.eval()\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1) ## Get highest probability class\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "                pred_labels.extend(predicted.cpu().numpy())\n",
    "    \n",
    "        \n",
    "        return classification_report(true_labels, pred_labels, target_names=selected_classes)\n",
    "        \n",
    "    # Evaluate and print model performance on test set    \n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    a = evaluate_model(model, test_loader, device)\n",
    "    print(a)\n",
    "\n",
    "    # Evaluate and print model performance on training set\n",
    "    print(\"\\nTraining Set Performance:\")\n",
    "    b = evaluate_model(model, train_loader, device)\n",
    "    print(b)\n",
    "    \n",
    "    # Return both performance reports\n",
    "    return (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Evaluating classes [0, 1] ===\n",
      "Selected classes: ['airplane', 'automobile']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.50      1.00      0.67      1000\n",
      "  automobile       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.50      1.00      0.67      5000\n",
      "  automobile       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [0, 2] ===\n",
      "Selected classes: ['airplane', 'bird']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.84      0.73      0.78      1000\n",
      "        bird       0.76      0.86      0.81      1000\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.80      0.80      0.80      2000\n",
      "weighted avg       0.80      0.80      0.80      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.86      0.77      0.81      5000\n",
      "        bird       0.79      0.87      0.83      5000\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [0, 3] ===\n",
      "Selected classes: ['airplane', 'cat']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.86      0.82      0.84      1000\n",
      "         cat       0.83      0.87      0.85      1000\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.89      0.84      0.86      5000\n",
      "         cat       0.85      0.89      0.87      5000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [0, 4] ===\n",
      "Selected classes: ['airplane', 'deer']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.50      1.00      0.67      1000\n",
      "        deer       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.50      1.00      0.67      5000\n",
      "        deer       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [0, 5] ===\n",
      "Selected classes: ['airplane', 'dog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.50      1.00      0.67      1000\n",
      "         dog       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.50      1.00      0.67      5000\n",
      "         dog       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [0, 6] ===\n",
      "Selected classes: ['airplane', 'frog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.90      0.78      0.83      1000\n",
      "        frog       0.80      0.91      0.85      1000\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.85      0.84      0.84      2000\n",
      "weighted avg       0.85      0.84      0.84      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.92      0.79      0.85      5000\n",
      "        frog       0.81      0.93      0.87      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [0, 7] ===\n",
      "Selected classes: ['airplane', 'horse']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.90      0.84      0.87      1000\n",
      "       horse       0.85      0.90      0.88      1000\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.87      0.87      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.91      0.84      0.88      5000\n",
      "       horse       0.85      0.92      0.89      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [0, 8] ===\n",
      "Selected classes: ['airplane', 'ship']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.00      0.00      0.00      1000\n",
      "        ship       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.00      0.00      0.00      5000\n",
      "        ship       0.50      1.00      0.67      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [0, 9] ===\n",
      "Selected classes: ['airplane', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.89      0.77      0.82      1000\n",
      "       truck       0.80      0.91      0.85      1000\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.92      0.78      0.85      5000\n",
      "       truck       0.81      0.93      0.87      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [1, 2] ===\n",
      "Selected classes: ['automobile', 'bird']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.93      0.83      0.87      1000\n",
      "        bird       0.84      0.94      0.89      1000\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.89      0.88      0.88      2000\n",
      "weighted avg       0.89      0.88      0.88      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.95      0.85      0.90      5000\n",
      "        bird       0.86      0.95      0.91      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.91      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [1, 3] ===\n",
      "Selected classes: ['automobile', 'cat']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.90      0.87      0.88      1000\n",
      "         cat       0.87      0.91      0.89      1000\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.89      0.89      0.89      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.92      0.88      0.90      5000\n",
      "         cat       0.89      0.92      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [1, 4] ===\n",
      "Selected classes: ['automobile', 'deer']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.50      1.00      0.67      1000\n",
      "        deer       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.50      1.00      0.67      5000\n",
      "        deer       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [1, 5] ===\n",
      "Selected classes: ['automobile', 'dog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.96      0.81      0.88      1000\n",
      "         dog       0.84      0.96      0.90      1000\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.90      0.89      0.89      2000\n",
      "weighted avg       0.90      0.89      0.89      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.96      0.82      0.88      5000\n",
      "         dog       0.84      0.97      0.90      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.90      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [1, 6] ===\n",
      "Selected classes: ['automobile', 'frog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.84      0.89      0.86      1000\n",
      "        frog       0.88      0.83      0.86      1000\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.85      0.91      0.88      5000\n",
      "        frog       0.91      0.83      0.87      5000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [1, 7] ===\n",
      "Selected classes: ['automobile', 'horse']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.90      0.81      0.85      1000\n",
      "       horse       0.83      0.91      0.87      1000\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.90      0.80      0.85      5000\n",
      "       horse       0.82      0.91      0.86      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [1, 8] ===\n",
      "Selected classes: ['automobile', 'ship']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.92      0.68      0.78      1000\n",
      "        ship       0.75      0.94      0.83      1000\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.83      0.81      0.81      2000\n",
      "weighted avg       0.83      0.81      0.81      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.93      0.70      0.80      5000\n",
      "        ship       0.76      0.94      0.84      5000\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.84      0.82      0.82     10000\n",
      "weighted avg       0.84      0.82      0.82     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [1, 9] ===\n",
      "Selected classes: ['automobile', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.00      0.00      0.00      1000\n",
      "       truck       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  automobile       0.00      0.00      0.00      5000\n",
      "       truck       0.50      1.00      0.67      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [2, 3] ===\n",
      "Selected classes: ['bird', 'cat']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.50      1.00      0.67      1000\n",
      "         cat       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.50      1.00      0.67      5000\n",
      "         cat       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [2, 4] ===\n",
      "Selected classes: ['bird', 'deer']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.00      0.00      0.00      1000\n",
      "        deer       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.00      0.00      0.00      5000\n",
      "        deer       0.50      1.00      0.67      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [2, 5] ===\n",
      "Selected classes: ['bird', 'dog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.50      1.00      0.67      1000\n",
      "         dog       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.50      1.00      0.67      5000\n",
      "         dog       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [2, 6] ===\n",
      "Selected classes: ['bird', 'frog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.73      0.80      0.76      1000\n",
      "        frog       0.78      0.71      0.74      1000\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.76      0.75      0.75      2000\n",
      "weighted avg       0.76      0.75      0.75      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.77      0.83      0.80      5000\n",
      "        frog       0.81      0.75      0.78      5000\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [2, 7] ===\n",
      "Selected classes: ['bird', 'horse']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.00      0.00      0.00      1000\n",
      "       horse       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.00      0.00      0.00      5000\n",
      "       horse       0.50      1.00      0.67      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [2, 8] ===\n",
      "Selected classes: ['bird', 'ship']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.00      0.00      0.00      1000\n",
      "        ship       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.00      0.00      0.00      5000\n",
      "        ship       0.50      1.00      0.67      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [2, 9] ===\n",
      "Selected classes: ['bird', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.92      0.84      0.87      1000\n",
      "       truck       0.85      0.92      0.89      1000\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.88      0.88      0.88      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.93      0.85      0.89      5000\n",
      "       truck       0.86      0.94      0.90      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.90      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [3, 4] ===\n",
      "Selected classes: ['cat', 'deer']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.50      1.00      0.67      1000\n",
      "        deer       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.50      1.00      0.67      5000\n",
      "        deer       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [3, 5] ===\n",
      "Selected classes: ['cat', 'dog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.61      0.73      0.67      1000\n",
      "         dog       0.67      0.54      0.60      1000\n",
      "\n",
      "    accuracy                           0.64      2000\n",
      "   macro avg       0.64      0.64      0.63      2000\n",
      "weighted avg       0.64      0.64      0.63      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.64      0.77      0.70      5000\n",
      "         dog       0.71      0.57      0.63      5000\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.68      0.67      0.67     10000\n",
      "weighted avg       0.68      0.67      0.67     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [3, 6] ===\n",
      "Selected classes: ['cat', 'frog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.77      0.80      0.78      1000\n",
      "        frog       0.79      0.76      0.77      1000\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.78      0.78      0.78      2000\n",
      "weighted avg       0.78      0.78      0.78      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.78      0.83      0.80      5000\n",
      "        frog       0.82      0.76      0.79      5000\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [3, 7] ===\n",
      "Selected classes: ['cat', 'horse']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.50      1.00      0.67      1000\n",
      "       horse       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.50      1.00      0.67      5000\n",
      "       horse       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [3, 8] ===\n",
      "Selected classes: ['cat', 'ship']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.00      0.00      0.00      1000\n",
      "        ship       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.00      0.00      0.00      5000\n",
      "        ship       0.50      1.00      0.67      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [3, 9] ===\n",
      "Selected classes: ['cat', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.88      0.84      0.86      1000\n",
      "       truck       0.85      0.88      0.87      1000\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.90      0.87      0.88      5000\n",
      "       truck       0.87      0.90      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [4, 5] ===\n",
      "Selected classes: ['deer', 'dog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.50      1.00      0.67      1000\n",
      "         dog       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.50      1.00      0.67      5000\n",
      "         dog       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [4, 6] ===\n",
      "Selected classes: ['deer', 'frog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.72      0.86      0.79      1000\n",
      "        frog       0.83      0.67      0.74      1000\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.78      0.77      0.76      2000\n",
      "weighted avg       0.78      0.77      0.76      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.73      0.90      0.81      5000\n",
      "        frog       0.87      0.66      0.76      5000\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.80      0.78      0.78     10000\n",
      "weighted avg       0.80      0.78      0.78     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [4, 7] ===\n",
      "Selected classes: ['deer', 'horse']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.50      1.00      0.67      1000\n",
      "       horse       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.50      1.00      0.67      5000\n",
      "       horse       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [4, 8] ===\n",
      "Selected classes: ['deer', 'ship']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.80      0.92      0.85      1000\n",
      "        ship       0.91      0.76      0.83      1000\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.85      0.84      0.84      2000\n",
      "weighted avg       0.85      0.84      0.84      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.81      0.92      0.86      5000\n",
      "        ship       0.90      0.78      0.84      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [4, 9] ===\n",
      "Selected classes: ['deer', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.88      0.91      0.90      1000\n",
      "       truck       0.91      0.88      0.89      1000\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.89      0.89      0.89      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        deer       0.89      0.91      0.90      5000\n",
      "       truck       0.91      0.89      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [5, 6] ===\n",
      "Selected classes: ['dog', 'frog']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.84      0.72      0.78      1000\n",
      "        frog       0.75      0.87      0.81      1000\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.80      0.79      0.79      2000\n",
      "weighted avg       0.80      0.79      0.79      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.86      0.73      0.79      5000\n",
      "        frog       0.77      0.88      0.82      5000\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [5, 7] ===\n",
      "Selected classes: ['dog', 'horse']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.00      0.00      0.00      1000\n",
      "       horse       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.00      0.00      0.00      5000\n",
      "       horse       0.50      1.00      0.67      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [5, 8] ===\n",
      "Selected classes: ['dog', 'ship']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.92      0.89      0.90      1000\n",
      "        ship       0.89      0.92      0.91      1000\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.91      0.91      0.91      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.92      0.92      0.92      5000\n",
      "        ship       0.92      0.92      0.92      5000\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [5, 9] ===\n",
      "Selected classes: ['dog', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.88      0.94      0.91      1000\n",
      "       truck       0.93      0.88      0.90      1000\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.91      0.91      0.91      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.89      0.94      0.91      5000\n",
      "       truck       0.93      0.88      0.91      5000\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [6, 7] ===\n",
      "Selected classes: ['frog', 'horse']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        frog       0.50      1.00      0.67      1000\n",
      "       horse       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        frog       0.50      1.00      0.67      5000\n",
      "       horse       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [6, 8] ===\n",
      "Selected classes: ['frog', 'ship']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        frog       0.00      0.00      0.00      1000\n",
      "        ship       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        frog       0.00      0.00      0.00      5000\n",
      "        ship       0.50      1.00      0.67      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [6, 9] ===\n",
      "Selected classes: ['frog', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        frog       0.80      0.92      0.85      1000\n",
      "       truck       0.91      0.76      0.83      1000\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.85      0.84      0.84      2000\n",
      "weighted avg       0.85      0.84      0.84      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        frog       0.84      0.95      0.89      5000\n",
      "       truck       0.94      0.81      0.87      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [7, 8] ===\n",
      "Selected classes: ['horse', 'ship']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       horse       0.50      1.00      0.67      1000\n",
      "        ship       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sujeetamberkar/miniconda3/envs/cwq/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       horse       0.50      1.00      0.67      5000\n",
      "        ship       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [7, 9] ===\n",
      "Selected classes: ['horse', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       horse       0.85      0.88      0.87      1000\n",
      "       truck       0.88      0.84      0.86      1000\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       horse       0.86      0.89      0.87      5000\n",
      "       truck       0.89      0.85      0.87      5000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluating classes [8, 9] ===\n",
      "Selected classes: ['ship', 'truck']\n",
      "Using device: mps\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ship       0.79      0.92      0.85      1000\n",
      "       truck       0.91      0.76      0.82      1000\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.85      0.84      0.84      2000\n",
      "weighted avg       0.85      0.84      0.84      2000\n",
      "\n",
      "\n",
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ship       0.81      0.94      0.87      5000\n",
      "       truck       0.93      0.78      0.85      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "claaisifcation_report_list = []\n",
    "for i in a:\n",
    "    claaisifcation_report_list.append(evaluate(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('              precision    recall  f1-score   support\\n\\n    airplane       0.50      1.00      0.67      1000\\n  automobile       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.50      1.00      0.67      5000\\n  automobile       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n    airplane       0.84      0.73      0.78      1000\\n        bird       0.76      0.86      0.81      1000\\n\\n    accuracy                           0.80      2000\\n   macro avg       0.80      0.80      0.80      2000\\nweighted avg       0.80      0.80      0.80      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.86      0.77      0.81      5000\\n        bird       0.79      0.87      0.83      5000\\n\\n    accuracy                           0.82     10000\\n   macro avg       0.82      0.82      0.82     10000\\nweighted avg       0.82      0.82      0.82     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n    airplane       0.86      0.82      0.84      1000\\n         cat       0.83      0.87      0.85      1000\\n\\n    accuracy                           0.84      2000\\n   macro avg       0.84      0.84      0.84      2000\\nweighted avg       0.84      0.84      0.84      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.89      0.84      0.86      5000\\n         cat       0.85      0.89      0.87      5000\\n\\n    accuracy                           0.87     10000\\n   macro avg       0.87      0.87      0.87     10000\\nweighted avg       0.87      0.87      0.87     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n    airplane       0.50      1.00      0.67      1000\\n        deer       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.50      1.00      0.67      5000\\n        deer       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n    airplane       0.50      1.00      0.67      1000\\n         dog       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.50      1.00      0.67      5000\\n         dog       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n    airplane       0.90      0.78      0.83      1000\\n        frog       0.80      0.91      0.85      1000\\n\\n    accuracy                           0.84      2000\\n   macro avg       0.85      0.84      0.84      2000\\nweighted avg       0.85      0.84      0.84      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.92      0.79      0.85      5000\\n        frog       0.81      0.93      0.87      5000\\n\\n    accuracy                           0.86     10000\\n   macro avg       0.86      0.86      0.86     10000\\nweighted avg       0.86      0.86      0.86     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n    airplane       0.90      0.84      0.87      1000\\n       horse       0.85      0.90      0.88      1000\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.87      0.87      0.87      2000\\nweighted avg       0.87      0.87      0.87      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.91      0.84      0.88      5000\\n       horse       0.85      0.92      0.89      5000\\n\\n    accuracy                           0.88     10000\\n   macro avg       0.88      0.88      0.88     10000\\nweighted avg       0.88      0.88      0.88     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n    airplane       0.00      0.00      0.00      1000\\n        ship       0.50      1.00      0.67      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.00      0.00      0.00      5000\\n        ship       0.50      1.00      0.67      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n    airplane       0.89      0.77      0.82      1000\\n       truck       0.80      0.91      0.85      1000\\n\\n    accuracy                           0.84      2000\\n   macro avg       0.84      0.84      0.84      2000\\nweighted avg       0.84      0.84      0.84      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n    airplane       0.92      0.78      0.85      5000\\n       truck       0.81      0.93      0.87      5000\\n\\n    accuracy                           0.86     10000\\n   macro avg       0.87      0.86      0.86     10000\\nweighted avg       0.87      0.86      0.86     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n  automobile       0.93      0.83      0.87      1000\\n        bird       0.84      0.94      0.89      1000\\n\\n    accuracy                           0.88      2000\\n   macro avg       0.89      0.88      0.88      2000\\nweighted avg       0.89      0.88      0.88      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n  automobile       0.95      0.85      0.90      5000\\n        bird       0.86      0.95      0.91      5000\\n\\n    accuracy                           0.90     10000\\n   macro avg       0.91      0.90      0.90     10000\\nweighted avg       0.91      0.90      0.90     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n  automobile       0.90      0.87      0.88      1000\\n         cat       0.87      0.91      0.89      1000\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.89      0.89      0.89      2000\\nweighted avg       0.89      0.89      0.89      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n  automobile       0.92      0.88      0.90      5000\\n         cat       0.89      0.92      0.90      5000\\n\\n    accuracy                           0.90     10000\\n   macro avg       0.90      0.90      0.90     10000\\nweighted avg       0.90      0.90      0.90     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n  automobile       0.50      1.00      0.67      1000\\n        deer       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n  automobile       0.50      1.00      0.67      5000\\n        deer       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n  automobile       0.96      0.81      0.88      1000\\n         dog       0.84      0.96      0.90      1000\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.90      0.89      0.89      2000\\nweighted avg       0.90      0.89      0.89      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n  automobile       0.96      0.82      0.88      5000\\n         dog       0.84      0.97      0.90      5000\\n\\n    accuracy                           0.89     10000\\n   macro avg       0.90      0.89      0.89     10000\\nweighted avg       0.90      0.89      0.89     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n  automobile       0.84      0.89      0.86      1000\\n        frog       0.88      0.83      0.86      1000\\n\\n    accuracy                           0.86      2000\\n   macro avg       0.86      0.86      0.86      2000\\nweighted avg       0.86      0.86      0.86      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n  automobile       0.85      0.91      0.88      5000\\n        frog       0.91      0.83      0.87      5000\\n\\n    accuracy                           0.87     10000\\n   macro avg       0.88      0.87      0.87     10000\\nweighted avg       0.88      0.87      0.87     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n  automobile       0.90      0.81      0.85      1000\\n       horse       0.83      0.91      0.87      1000\\n\\n    accuracy                           0.86      2000\\n   macro avg       0.86      0.86      0.86      2000\\nweighted avg       0.86      0.86      0.86      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n  automobile       0.90      0.80      0.85      5000\\n       horse       0.82      0.91      0.86      5000\\n\\n    accuracy                           0.86     10000\\n   macro avg       0.86      0.86      0.86     10000\\nweighted avg       0.86      0.86      0.86     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n  automobile       0.92      0.68      0.78      1000\\n        ship       0.75      0.94      0.83      1000\\n\\n    accuracy                           0.81      2000\\n   macro avg       0.83      0.81      0.81      2000\\nweighted avg       0.83      0.81      0.81      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n  automobile       0.93      0.70      0.80      5000\\n        ship       0.76      0.94      0.84      5000\\n\\n    accuracy                           0.82     10000\\n   macro avg       0.84      0.82      0.82     10000\\nweighted avg       0.84      0.82      0.82     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n  automobile       0.00      0.00      0.00      1000\\n       truck       0.50      1.00      0.67      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n  automobile       0.00      0.00      0.00      5000\\n       truck       0.50      1.00      0.67      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        bird       0.50      1.00      0.67      1000\\n         cat       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        bird       0.50      1.00      0.67      5000\\n         cat       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        bird       0.00      0.00      0.00      1000\\n        deer       0.50      1.00      0.67      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        bird       0.00      0.00      0.00      5000\\n        deer       0.50      1.00      0.67      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        bird       0.50      1.00      0.67      1000\\n         dog       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        bird       0.50      1.00      0.67      5000\\n         dog       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        bird       0.73      0.80      0.76      1000\\n        frog       0.78      0.71      0.74      1000\\n\\n    accuracy                           0.75      2000\\n   macro avg       0.76      0.75      0.75      2000\\nweighted avg       0.76      0.75      0.75      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        bird       0.77      0.83      0.80      5000\\n        frog       0.81      0.75      0.78      5000\\n\\n    accuracy                           0.79     10000\\n   macro avg       0.79      0.79      0.79     10000\\nweighted avg       0.79      0.79      0.79     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        bird       0.00      0.00      0.00      1000\\n       horse       0.50      1.00      0.67      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        bird       0.00      0.00      0.00      5000\\n       horse       0.50      1.00      0.67      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        bird       0.00      0.00      0.00      1000\\n        ship       0.50      1.00      0.67      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        bird       0.00      0.00      0.00      5000\\n        ship       0.50      1.00      0.67      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        bird       0.92      0.84      0.87      1000\\n       truck       0.85      0.92      0.89      1000\\n\\n    accuracy                           0.88      2000\\n   macro avg       0.88      0.88      0.88      2000\\nweighted avg       0.88      0.88      0.88      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        bird       0.93      0.85      0.89      5000\\n       truck       0.86      0.94      0.90      5000\\n\\n    accuracy                           0.89     10000\\n   macro avg       0.90      0.89      0.89     10000\\nweighted avg       0.90      0.89      0.89     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         cat       0.50      1.00      0.67      1000\\n        deer       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         cat       0.50      1.00      0.67      5000\\n        deer       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         cat       0.61      0.73      0.67      1000\\n         dog       0.67      0.54      0.60      1000\\n\\n    accuracy                           0.64      2000\\n   macro avg       0.64      0.64      0.63      2000\\nweighted avg       0.64      0.64      0.63      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         cat       0.64      0.77      0.70      5000\\n         dog       0.71      0.57      0.63      5000\\n\\n    accuracy                           0.67     10000\\n   macro avg       0.68      0.67      0.67     10000\\nweighted avg       0.68      0.67      0.67     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         cat       0.77      0.80      0.78      1000\\n        frog       0.79      0.76      0.77      1000\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.78      0.78      0.78      2000\\nweighted avg       0.78      0.78      0.78      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         cat       0.78      0.83      0.80      5000\\n        frog       0.82      0.76      0.79      5000\\n\\n    accuracy                           0.80     10000\\n   macro avg       0.80      0.80      0.80     10000\\nweighted avg       0.80      0.80      0.80     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         cat       0.50      1.00      0.67      1000\\n       horse       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         cat       0.50      1.00      0.67      5000\\n       horse       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         cat       0.00      0.00      0.00      1000\\n        ship       0.50      1.00      0.67      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         cat       0.00      0.00      0.00      5000\\n        ship       0.50      1.00      0.67      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         cat       0.88      0.84      0.86      1000\\n       truck       0.85      0.88      0.87      1000\\n\\n    accuracy                           0.86      2000\\n   macro avg       0.86      0.86      0.86      2000\\nweighted avg       0.86      0.86      0.86      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         cat       0.90      0.87      0.88      5000\\n       truck       0.87      0.90      0.89      5000\\n\\n    accuracy                           0.89     10000\\n   macro avg       0.89      0.89      0.89     10000\\nweighted avg       0.89      0.89      0.89     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        deer       0.50      1.00      0.67      1000\\n         dog       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        deer       0.50      1.00      0.67      5000\\n         dog       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        deer       0.72      0.86      0.79      1000\\n        frog       0.83      0.67      0.74      1000\\n\\n    accuracy                           0.77      2000\\n   macro avg       0.78      0.77      0.76      2000\\nweighted avg       0.78      0.77      0.76      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        deer       0.73      0.90      0.81      5000\\n        frog       0.87      0.66      0.76      5000\\n\\n    accuracy                           0.78     10000\\n   macro avg       0.80      0.78      0.78     10000\\nweighted avg       0.80      0.78      0.78     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        deer       0.50      1.00      0.67      1000\\n       horse       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        deer       0.50      1.00      0.67      5000\\n       horse       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        deer       0.80      0.92      0.85      1000\\n        ship       0.91      0.76      0.83      1000\\n\\n    accuracy                           0.84      2000\\n   macro avg       0.85      0.84      0.84      2000\\nweighted avg       0.85      0.84      0.84      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        deer       0.81      0.92      0.86      5000\\n        ship       0.90      0.78      0.84      5000\\n\\n    accuracy                           0.85     10000\\n   macro avg       0.86      0.85      0.85     10000\\nweighted avg       0.86      0.85      0.85     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        deer       0.88      0.91      0.90      1000\\n       truck       0.91      0.88      0.89      1000\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.89      0.89      0.89      2000\\nweighted avg       0.89      0.89      0.89      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        deer       0.89      0.91      0.90      5000\\n       truck       0.91      0.89      0.90      5000\\n\\n    accuracy                           0.90     10000\\n   macro avg       0.90      0.90      0.90     10000\\nweighted avg       0.90      0.90      0.90     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         dog       0.84      0.72      0.78      1000\\n        frog       0.75      0.87      0.81      1000\\n\\n    accuracy                           0.79      2000\\n   macro avg       0.80      0.79      0.79      2000\\nweighted avg       0.80      0.79      0.79      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         dog       0.86      0.73      0.79      5000\\n        frog       0.77      0.88      0.82      5000\\n\\n    accuracy                           0.81     10000\\n   macro avg       0.81      0.81      0.81     10000\\nweighted avg       0.81      0.81      0.81     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         dog       0.00      0.00      0.00      1000\\n       horse       0.50      1.00      0.67      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         dog       0.00      0.00      0.00      5000\\n       horse       0.50      1.00      0.67      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         dog       0.92      0.89      0.90      1000\\n        ship       0.89      0.92      0.91      1000\\n\\n    accuracy                           0.91      2000\\n   macro avg       0.91      0.91      0.91      2000\\nweighted avg       0.91      0.91      0.91      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         dog       0.92      0.92      0.92      5000\\n        ship       0.92      0.92      0.92      5000\\n\\n    accuracy                           0.92     10000\\n   macro avg       0.92      0.92      0.92     10000\\nweighted avg       0.92      0.92      0.92     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n         dog       0.88      0.94      0.91      1000\\n       truck       0.93      0.88      0.90      1000\\n\\n    accuracy                           0.91      2000\\n   macro avg       0.91      0.91      0.91      2000\\nweighted avg       0.91      0.91      0.91      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n         dog       0.89      0.94      0.91      5000\\n       truck       0.93      0.88      0.91      5000\\n\\n    accuracy                           0.91     10000\\n   macro avg       0.91      0.91      0.91     10000\\nweighted avg       0.91      0.91      0.91     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        frog       0.50      1.00      0.67      1000\\n       horse       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        frog       0.50      1.00      0.67      5000\\n       horse       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        frog       0.00      0.00      0.00      1000\\n        ship       0.50      1.00      0.67      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        frog       0.00      0.00      0.00      5000\\n        ship       0.50      1.00      0.67      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        frog       0.80      0.92      0.85      1000\\n       truck       0.91      0.76      0.83      1000\\n\\n    accuracy                           0.84      2000\\n   macro avg       0.85      0.84      0.84      2000\\nweighted avg       0.85      0.84      0.84      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        frog       0.84      0.95      0.89      5000\\n       truck       0.94      0.81      0.87      5000\\n\\n    accuracy                           0.88     10000\\n   macro avg       0.89      0.88      0.88     10000\\nweighted avg       0.89      0.88      0.88     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n       horse       0.50      1.00      0.67      1000\\n        ship       0.00      0.00      0.00      1000\\n\\n    accuracy                           0.50      2000\\n   macro avg       0.25      0.50      0.33      2000\\nweighted avg       0.25      0.50      0.33      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n       horse       0.50      1.00      0.67      5000\\n        ship       0.00      0.00      0.00      5000\\n\\n    accuracy                           0.50     10000\\n   macro avg       0.25      0.50      0.33     10000\\nweighted avg       0.25      0.50      0.33     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n       horse       0.85      0.88      0.87      1000\\n       truck       0.88      0.84      0.86      1000\\n\\n    accuracy                           0.86      2000\\n   macro avg       0.86      0.86      0.86      2000\\nweighted avg       0.86      0.86      0.86      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n       horse       0.86      0.89      0.87      5000\\n       truck       0.89      0.85      0.87      5000\\n\\n    accuracy                           0.87     10000\\n   macro avg       0.87      0.87      0.87     10000\\nweighted avg       0.87      0.87      0.87     10000\\n'),\n",
       " ('              precision    recall  f1-score   support\\n\\n        ship       0.79      0.92      0.85      1000\\n       truck       0.91      0.76      0.82      1000\\n\\n    accuracy                           0.84      2000\\n   macro avg       0.85      0.84      0.84      2000\\nweighted avg       0.85      0.84      0.84      2000\\n',\n",
       "  '              precision    recall  f1-score   support\\n\\n        ship       0.81      0.94      0.87      5000\\n       truck       0.93      0.78      0.85      5000\\n\\n    accuracy                           0.86     10000\\n   macro avg       0.87      0.86      0.86     10000\\nweighted avg       0.87      0.86      0.86     10000\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claaisifcation_report_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
